{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "# SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "# sc = SparkContext(\"local\", \"App Name\")\n",
    "from pyspark.sql.functions import count, udf, collect_set\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_parquet('/scratch/hk3820/train_data_all.parquet')\n",
    "valData = pd.read_parquet('/scratch/hk3820/val_data_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cnts = valData[['user_id', 'recording_mbid', 'timestamp']].groupby(['user_id','recording_mbid'])['timestamp'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cnts.reset_index().to_parquet('BigDataProject/Datasets/valData_final.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData[['user_id', 'recording_mbid']]\n",
    "trainData.columns = ['user_id', 'item_id']\n",
    "\n",
    "valData = valData[['user_id', 'recording_mbid']]\n",
    "valData.columns = ['user_id', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = Dataset()\n",
    "td.fit(users=trainData['user_id'], items=trainData['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = td.mapping()\n",
    "pickle.dump(maps[0], open('user_id_map.pkl', 'wb'))\n",
    "pickle.dump(maps[2], open('item_id_map.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 7852, num_items 21069152.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = td.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_dataset = td.build_interactions(data=list(zip(trainData.user_id, trainData.item_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = valData[valData['user_id'].isin(trainData['user_id']) & valData['item_id'].isin(trainData['item_id'])]\n",
    "val_sparse_dataset = td.build_interactions(data=list(zip(valData.user_id, valData.item_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(\"validation.npz\", val_sparse_dataset[0])\n",
    "sparse.save_npz(\"train.npz\", train_sparse_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_sparse_dataset, \n",
    "                item_alpha=0.0, \n",
    "                user_alpha=0.0, \n",
    "                no_components=10, \n",
    "                loss='warp', \n",
    "                random_state=42, \n",
    "                num_epochs=10, \n",
    "                num_threads=8,\n",
    "                verbose=True):\n",
    "    \"\"\"\n",
    "    Trains a LightFM model given the model parameters\n",
    "    \"\"\"\n",
    "    model = LightFM(loss=loss, \n",
    "                    random_state=random_state, \n",
    "                    no_components=no_components, \n",
    "                    item_alpha=item_alpha, \n",
    "                    user_alpha=user_alpha)\n",
    "    model.fit(train_sparse_dataset, \n",
    "              epochs=num_epochs, \n",
    "              verbose=verbose, \n",
    "              num_threads=num_threads)\n",
    "    return model\n",
    "\n",
    "def save_model(model, modelfilename):\n",
    "    \"\"\"\n",
    "    Saves a LightFM model\n",
    "    \"\"\"\n",
    "    pickle.dump(model, open(modelfilename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(model_fn, save_fn, user_map_fn='BigDataProject/Maps/user_id_map.pkl', item_map_fn='BigDataProject/Maps/item_id_map.pkl'):\n",
    "    \"\"\"\n",
    "    Generate Recommendations for a given model\n",
    "    \"\"\"\n",
    "    recommendations = pd.DataFrame(columns=['user_id', 'recommendations'])\n",
    "    \n",
    "    #Loading files\n",
    "    print('Loading Model and Map Files...')\n",
    "    model = pickle.load(open(model_fn, 'rb'))\n",
    "    user_map = pickle.load(open(user_map_fn, 'rb'))\n",
    "    item_map = pickle.load(open(item_map_fn, 'rb'))\n",
    "    \n",
    "    user_map = {v: k for k, v in user_map.items()}\n",
    "    item_map = {v: k for k, v in item_map.items()}\n",
    "    \n",
    "    #Getting user and item representations\n",
    "    print('Getting User and Item Representations...')\n",
    "    item_repr = model.get_item_representations()\n",
    "    user_repr = model.get_user_representations()\n",
    "    \n",
    "    item_bias = item_repr[0]\n",
    "    item_weights = item_repr[1]\n",
    "\n",
    "    user_bias = user_repr[0]\n",
    "    user_weights = user_repr[1]\n",
    "    \n",
    "    print(\"Generating Representations...\")\n",
    "    for i in tqdm(range(user_weights.shape[0])):\n",
    "        user_embedding = user_weights[i]\n",
    "        scores = user_embedding@item_weights.T\n",
    "        scores += user_bias[i]\n",
    "        scores = np.add(scores, item_bias)\n",
    "        sorted_indices = np.argpartition(scores, -100)[-100:][::-1]\n",
    "        user_id = user_map[i]\n",
    "        item_mbids = [item_map[j] for j in sorted_indices]\n",
    "        recommendations = recommendations.append({'user_id': user_id, 'recommendations': item_mbids}, ignore_index=True)\n",
    "        \n",
    "    print(\"Saving Recommendations...\")\n",
    "    recommendations.to_parquet(save_fn, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(validation_fn, recommendation_fn, k=100):\n",
    "    spark = SparkSession.builder.config('spark.executor.memory', '70g').config('spark.driver.memory', '50g').config('spark.storage.memoryFraction', '0.05').appName(\"recsys\").getOrCreate()\n",
    "    val_df = val_df = spark.read.parquet(validation_fn, schema=\"recording_mbid INT, user_id INT, timestamp INT\")\n",
    "    reco_df = spark.read.parquet(recommendation_fn, schema=\"user_id INT, recommendations ARRAY\")\n",
    "    val_df = val_df.groupby(\"user_id\").agg(collect_set(\"recording_mbid\").alias('true_items'))\n",
    "    reco_and_labels_df = reco_df.join(val_df, \"user_id\", \"inner\")\n",
    "    reco_and_labels_rdd = reco_and_labels_df.rdd.map(lambda row: (row['recommendations'], row['true_items']))\n",
    "    metrics = RankingMetrics(reco_and_labels_rdd)\n",
    "    return metrics.precisionAt(k), metrics.meanAveragePrecisionAt(k), metrics.ndcgAt(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_fn,\n",
    "        validation_fn,\n",
    "        item_alpha=0.0, \n",
    "        user_alpha=0.0, \n",
    "        no_components=10, \n",
    "        loss='warp', \n",
    "        random_state=42, \n",
    "        num_epochs=10, \n",
    "        user_map = 'BigDataProject/Maps/user_id_map.pkl',\n",
    "        item_map = 'BigDataProject/Maps/item_id_map.pkl',\n",
    "        num_threads=8, \n",
    "        verbose=True):\n",
    "    \"\"\"\n",
    "    Full Run\n",
    "    \"\"\"\n",
    "    print('__________________________________________________\\n')\n",
    "    print(f'Item Alpha: {item_alpha}')\n",
    "    print(f'User Alpha: {user_alpha}')\n",
    "    print(f'Rank: {no_components}')\n",
    "    print('Loading Train Data...')\n",
    "    train_sparse_dataset = sparse.load_npz(train_fn)\n",
    "    modelfilename = f'BigDataProject/Models/model_item_alpha_{item_alpha}_user_alpha_{user_alpha}_rank_{no_components}.pkl'\n",
    "    recommendation_fn = f'BigDataProject/Recommendations/recommendation_item_alpha_{item_alpha}_user_alpha_{user_alpha}_rank_{no_components}.parquet'\n",
    "    print('Beginning Training...')\n",
    "    train_start = time.time()\n",
    "    model = train_model(train_sparse_dataset, \n",
    "                item_alpha=item_alpha, \n",
    "                user_alpha=user_alpha, \n",
    "                no_components=no_components, \n",
    "                loss=loss, \n",
    "                random_state=random_state, \n",
    "                num_epochs=num_epochs, \n",
    "                num_threads=num_threads,\n",
    "                verbose=verbose)\n",
    "    end = time.time()\n",
    "    time_taken_train = time.time() - train_start\n",
    "    print(f'Time Taken For Training: {int(time_taken_train//60)} minutes and {int(time_taken_train - (time_taken_train//60)*60)} seconds')\n",
    "    print('Saving Model...')\n",
    "    save_model(model, modelfilename)\n",
    "    print('Generating Recommendations...')\n",
    "    recommendation_start = time.time()\n",
    "    generate_recommendations(model_fn=modelfilename, save_fn=recommendation_fn)\n",
    "    time_taken_recommendation = time.time() - recommendation_start\n",
    "    print(f'Time Taken For Generating Recommendations: {int(time_taken_recommendation//60)} minutes and {int(time_taken_recommendation - (time_taken_recommendation//60)*60)} seconds')\n",
    "    print('Computing Metrics...')\n",
    "    precision, mapk, ndcg = compute_metrics(validation_fn, recommendation_fn)\n",
    "    print(f'Precision@100: {precision}')\n",
    "    print(f'MAP@100: {mapk}')\n",
    "    print(f'ndcg@100: {ndcg}')\n",
    "    return time_taken_train, time_taken_recommendation, precision, mapk, ndcg, modelfilename, recommendation_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction - Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1383703568827385, 0.054416945349210835, 0.14042539874020735)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = 'test_data.parquet'\n",
    "recommendations_fn = 'BigDataProject/Recommendations/recommendation_item_alpha_1e-06_user_alpha_1e-06_rank_25.parquet'\n",
    "compute_metrics(validation_fn=test_fn, recommendation_fn=recommendations_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Dataset - 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_parquet('data_20.parquet', engine='pyarrow')\n",
    "trainData = trainData[['user_id', 'interactions_count', 'recording_mbid']]\n",
    "trainData.columns = ['user_id', 'interactions_count', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = Dataset()\n",
    "td.fit(users=trainData['user_id'], items=trainData['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = td.mapping()\n",
    "pickle.dump(maps[0], open('user_id_map_20.pkl', 'wb'))\n",
    "pickle.dump(maps[2], open('item_id_map_20.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 7761, num_items 8557723.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = td.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_dataset = td.build_interactions(data=list(zip(trainData.user_id, trainData.item_id, trainData.interactions_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('train_20.npz', train_sparse_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "\n",
      "Item Alpha: 1e-06\n",
      "User Alpha: 1e-06\n",
      "Rank: 25\n",
      "Loading Train Data...\n",
      "Beginning Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [01:58<00:00, 11.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken For Training: 2 minutes and 1 seconds\n",
      "Saving Model...\n",
      "Generating Recommendations...\n",
      "Loading Model and Map Files...\n",
      "Getting User and Item Representations...\n",
      "Generating Representations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7761/7761 [16:19<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Recommendations...\n",
      "Time Taken For Generating Recommendations: 16 minutes and 33 seconds\n",
      "Computing Metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@100: 0.00018940858136838045\n",
      "MAP@100: 9.549585647220643e-06\n",
      "ndcg@100: 0.00018718254225636745\n"
     ]
    }
   ],
   "source": [
    "user_alpha_list = [1e-6]\n",
    "item_alpha_list = [1e-6]\n",
    "\n",
    "result_df = pd.DataFrame(columns=['user_alpha', 'item_alpha', 'rank', 'train_time', 'modelfilename','recommendation_time', 'recommendationfilename', 'precision@100', 'map@100', 'ndcg@100'])\n",
    "train_fn = 'train_20.npz'\n",
    "val_fn = 'BigDataProject/Datasets/valData_final.parquet'\n",
    "\n",
    "for ua in user_alpha_list:\n",
    "    for ia in item_alpha_list:\n",
    "        time_train, time_rec, p, m, n, model_fn, recommendation_fn = run(train_fn=train_fn, validation_fn=val_fn, user_alpha=ua, item_alpha=ia, no_components=25, user_map='user_id_map_20.pkl', item_map='item_id_map_20.pkl')\n",
    "        result_df = result_df.append({\n",
    "            'user_alpha': ua,\n",
    "            'item_alpha': ia,\n",
    "            'rank': 25,\n",
    "            'train_time': time_train,\n",
    "            'modelfilename': model_fn,\n",
    "            'recommendation_time': time_rec,\n",
    "            'recommendationfilename': recommendation_fn,\n",
    "            'precision@100': p,\n",
    "            'map@100': m,\n",
    "            'ndcg@100': n\n",
    "        }, ignore_index=True)\n",
    "\n",
    "result_df.to_csv('BigDataProject/results_alpha_tuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00018774157923799007, 8.313237630545671e-06, 0.0001818402385415233)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = 'test_data.parquet'\n",
    "recommendations_fn = 'BigDataProject/Recommendations/recommendation_item_alpha_1e-06_user_alpha_1e-06_rank_25.parquet'\n",
    "compute_metrics(validation_fn=test_fn, recommendation_fn=recommendations_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Dataset - 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_parquet('data_50.parquet', engine='pyarrow')\n",
    "trainData = trainData[['user_id', 'interactions_count', 'recording_mbid']]\n",
    "trainData.columns = ['user_id', 'interactions_count', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = Dataset()\n",
    "td.fit(users=trainData['user_id'], items=trainData['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = td.mapping()\n",
    "pickle.dump(maps[0], open('user_id_map_50.pkl', 'wb'))\n",
    "pickle.dump(maps[2], open('item_id_map_50.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 7852, num_items 16154649.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = td.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_dataset = td.build_interactions(data=list(zip(trainData.user_id, trainData.item_id, trainData.interactions_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('train_50.npz', train_sparse_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_alpha_list = [1e-6]\n",
    "item_alpha_list = [1e-6]\n",
    "\n",
    "result_df = pd.DataFrame(columns=['user_alpha', 'item_alpha', 'rank', 'train_time', 'modelfilename','recommendation_time', 'recommendationfilename', 'precision@100', 'map@100', 'ndcg@100'])\n",
    "train_fn = 'train_50.npz'\n",
    "val_fn = 'BigDataProject/Datasets/valData_final.parquet'\n",
    "\n",
    "for ua in user_alpha_list:\n",
    "    for ia in item_alpha_list:\n",
    "        time_train, time_rec, p, m, n, model_fn, recommendation_fn = run(train_fn=train_fn, validation_fn=val_fn, user_alpha=ua, item_alpha=ia, no_components=25, user_map='user_id_map_50.pkl', item_map='item_id_map_50.pkl')\n",
    "        result_df = result_df.append({\n",
    "            'user_alpha': ua,\n",
    "            'item_alpha': ia,\n",
    "            'rank': 25,\n",
    "            'train_time': time_train,\n",
    "            'modelfilename': model_fn,\n",
    "            'recommendation_time': time_rec,\n",
    "            'recommendationfilename': recommendation_fn,\n",
    "            'precision@100': p,\n",
    "            'map@100': m,\n",
    "            'ndcg@100': n\n",
    "        }, ignore_index=True)\n",
    "\n",
    "result_df.to_csv('BigDataProject/results_alpha_tuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/ext3/miniconda3/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/16 02:45:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00012480896586856852, 5.984202228062866e-06, 0.0001221091303719588)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = 'BigDataProject/Datasets/valData_final.parquet'\n",
    "recommendations_fn = 'BigDataProject/Recommendations/recommendation_item_alpha_1e-06_user_alpha_1e-06_rank_25.parquet'\n",
    "compute_metrics(validation_fn=test_fn, recommendation_fn=recommendations_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0001584122359796067, 8.441638951592124e-06, 0.00015914219756867998)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = 'test_data.parquet'\n",
    "recommendations_fn = 'BigDataProject/Recommendations/recommendation_item_alpha_1e-06_user_alpha_1e-06_rank_25.parquet'\n",
    "compute_metrics(validation_fn=test_fn, recommendation_fn=recommendations_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13750636780438097, 0.047864021711044216, 0.13973971457784126)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fn = 'BigDataProject/Datasets/valData_final.parquet'\n",
    "recommendations_fn = 'BigDataProject/Recommendations/recommendation_item_alpha_1e-08_user_alpha_1e-08_rank_25.parquet'\n",
    "compute_metrics(validation_fn=test_fn, recommendation_fn=recommendations_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
